{
  "index": 1,
  "history": [
    {
      "timestamp": 1720194772126,
      "prompt": "Code Template",
      "response": "def compute(in1, in2):\n    \"\"\"A textual description of the compute function.\n\n    Inputs:\n        in1 (all): Textual description of in1\n        in2 (all): Textual description of in2\n\n    Outputs:\n        out1 (all): Textual description of out1\n        out2 (all): Textual description of out2\n\n    Requirements:\n    \"\"\"\n    # some code\n    out1 = 2 * in1\n    out2 = \"This is the in2 string:\" + in2\n\n    return {\"out1\": out1, \"out2\": out2}\n\n\ndef test():\n    \"\"\"Test the compute function.\"\"\"\n\n    print(\"Running test\")\n"
    },
    {
      "timestamp": 1720194838024,
      "prompt": "Manual edit of code #0",
      "response": "import pickle\nimport torch\nimport pandas as pd\nfrom tqdm import tqdm\nimport zipfile\n\ndef compute(test_dataset_file, model_processor_file, model_architecture_type, target_layer, saving_dir):\n        \"\"\"\n        lib:https://github.com/jacobgil/pytorch-grad-cam/tree/master?tab=readme-ov-file\n        targets are set to None: If targets is None, the highest scoring category\n        Need to wrap up the huggingface model to torch model.\n\n        model_architecture_type will be responsible for choosing the reshaping of the output tensors.\n        https://jacobgil.github.io/pytorch-gradcam-book/vision_transformers.html\n\n        target layers: list of target layers \n\n        -----------------------------------------------Theory:-----------------------------------------------------------\n\n        xai algorithms requires input of the layers which has output (Batch_size, Channels, w, h)\n\n        Batch_size: number of images.\n        Channels  : Features (for cnn number of kernels).\n        w, h      : size of the features (for cnn size of the kernels.)\n\n        for the transformer based architectures we need to construct the reshape_transform function.\n\n        what is reshape_transform function ?\n        To apply the xai on transformer architecture we need layers which has output (batchsize, patchsize*patchsize+1 or patchsize*patchsize, features.)\n        because it does not produce 2D feature maps as  cnn.\n        Once we get the output in this shape we need to transform it to match it (batch_size, features, patchsize, patchsize)\n\n        How to build reshape_transform function ?\n        For ViT : if the output shape is (1, 197, 192): 197 represents the number of tokens and the first one is for [cls] .\n                we ignore the first token so (1, 196, 192) -> (1, 14, 14, 192) ->( 1, 192, 14, 14 )[just like cnn]\n\n        For SwiT : there is no [cls] token in SwiT, so (1, 196, 192) -> (1, 14, 14, 192) ->( 1, 192, 14, 14 )[just like cnn]\n\n        For the Users:\n        select the suitable layer, that match the output shape as discribe above.\n\n        How to check which layers to select?\n\n        If you are using pre-train models and not sure about the summary.\n        Use \n\n        def print_model_summary(model, input_size, batch_size=-1, device=\"cuda\"):\n            from torchinfo import torchinfo\n            summary_info = torchinfo.summary(model, input_size=(batch_size, *input_size), device=device, verbose=2)\n            print(summary_info)\n\n        or try to print the model.\n\n        Some of the common choice for the target layers.\n\n        #my_model.resnet.encoder.stages[-1].layers[-1]\n        #my_model.vit.encoder.layer[-4].output\n        #my_model.swinv2.layernorm\n        \"\"\"\n\n        #, \"ScoreCAM\", \"AblationCAM\" this 2 are slow so, just opt out for now.\n        import numpy as np\n        from PIL import Image\n        import os\n        from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n        from pytorch_grad_cam.utils.image import show_cam_on_image\n\n        # Ensure the saving directory exists\n\n        if not os.path.exists(saving_dir):\n            os.makedirs(saving_dir)\n\n        # Unzip the test dataset file\n        with zipfile.ZipFile(test_dataset_file, 'r') as zip_ref:\n            zip_ref.extractall(saving_dir)\n\n        # Find the Excel file in the extracted folder\n        # Function to find the Excel file recursively\n        def find_excel_file(directory):\n            for root, dirs, files in os.walk(directory):\n                for file in files:\n                    if file.endswith('.xlsx'):\n                        return os.path.join(root, file)\n            return None\n        \n        # Find the Excel file in the extracted folder\n        excel_file = find_excel_file(saving_dir)\n        \n        if excel_file is None:\n            raise FileNotFoundError(\"Excel file not found in the unzipped directory.\")\n        \n        # Load the dataset from the Excel file\n        dataframe = pd.read_excel(excel_file)\n        \n        # Load the model and processor from the pickle file\n        with open(model_processor_file, 'rb') as f:\n            loaded_dict = pickle.load(f)\n        \n        model = loaded_dict['model']\n        processor = loaded_dict['processor']\n        model.eval()\n        \n\n        def reshape_transform_vit_huggingface(x):\n            activations = x[:, 1:, :]\n            x = np.sqrt(activations.shape[1])\n            activations = activations.view(activations.shape[0], int(x), int(x), activations.shape[2])\n            activations = activations.transpose(2, 3).transpose(1, 2)\n            return activations\n\n        def reshape_transform_SwiT_huggingface(x):\n            activations = x\n            x = np.sqrt(activations.shape[1])\n            activations = activations.view(activations.shape[0], int(x), int(x), activations.shape[2])\n            activations = activations.transpose(2, 3).transpose(1, 2)\n            return activations\n\n        if model_architecture_type == \"cnn\":\n            transform = None\n            xai_algo = [\"GradCAM\", \"HiResCAM\", \"GradCAMPlusPlus\", \"XGradCAM\", \"EigenCAM\"]\n            [os.makedirs(f\"{saving_dir}/xai/{algo}\", exist_ok=True) for algo in xai_algo]\n\n        if model_architecture_type == \"ViT\":\n            transform = reshape_transform_vit_huggingface\n            xai_algo = [\"GradCAM\", \"HiResCAM\", \"GradCAMPlusPlus\", \"XGradCAM\", \"EigenCAM\"]\n            [os.makedirs(f\"{saving_dir}/xai/{algo}\", exist_ok=True) for algo in xai_algo]\n\n        if model_architecture_type == \"SwiT\":\n            transform = reshape_transform_SwiT_huggingface\n            xai_algo = [\"GradCAM\", \"HiResCAM\", \"GradCAMPlusPlus\", \"XGradCAM\", \"EigenCAM\"]\n            [os.makedirs(f\"{saving_dir}/xai/{algo}\", exist_ok=True) for algo in xai_algo]\n\n        \n        target_layers = [eval(target_layer)]\n        GradCAM_, HiResCAM_, GradCAMPlusPlus_, XGradCAM_, EigenCAM_ = [], [], [], [], []\n        for algo in xai_algo:\n            for index, row in tqdm(dataframe.iterrows(), total=dataframe.shape[0]):\n                file_path = os.path.join(os.path.dirname(excel_file), row['filename'])\n                if not os.path.exists(file_path):\n                    print(f\"Image file {file_path} not found.\")\n                    continue\n                image = Image.open(file_path).convert(\"RGB\")\n                img_name = row['filename']\n                input_tensor = processor(image)\n                input_tensor = input_tensor.unsqueeze(0)\n                cam = eval(algo)(model=model, target_layers=target_layers, reshape_transform=transform)\n                targets = None\n\n                # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n                grayscale_cam = cam(input_tensor=input_tensor, targets=targets, aug_smooth=True, eigen_smooth=True)\n                # In this example grayscale_cam has only one image in the batch:\n                grayscale_cam = grayscale_cam[0, :]\n\n                w, h = grayscale_cam.shape[0], grayscale_cam.shape[1]\n                image = image.resize((w,h))\n                visualization = show_cam_on_image(np.array(image)/255, grayscale_cam, use_rgb=True)\n\n                img = Image.fromarray(visualization)\n                img.save(f\"{saving_dir}/xai/{algo}/{img_name}\")\n\n                eval(algo + \"_\").append(f\"{saving_dir}/xai/{algo}/{img_name}\")\n        return {\"GradCAM\":GradCAM_, \"HiResCAM\":HiResCAM_, \"GradCAMPlusPlus\":GradCAMPlusPlus_, \"XGradCAM\":XGradCAM_, \"EigenCAM\":EigenCAM_}\n\n\ndef test():\n    \"\"\"Test the compute function.\"\"\"\n\n    print(\"Running test\")\n"
    }
  ]
}